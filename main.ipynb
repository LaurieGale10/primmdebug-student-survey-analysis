{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRIMMDebug Student Survey Analysis\n",
    "\n",
    "This notebook contains a narrative of the code used to analyse the responses from the student survey taken after usage of PRIMMDebug. The goal of the survey was to understand students' perspectives towards PRIMMDebug, which could be triangulated with their actions within the PRIMMDebug tool.\n",
    "\n",
    "The analysis is split up into several sections:\n",
    "1. Summary statistics across the whole dataset.\n",
    "2. Factor analysis\n",
    "3. (Potentially) Alternative analysis\n",
    "4. An appendix of visualisations for each individual question response.\n",
    "\n",
    "First, let us import the necessary libraries and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "suppressPackageStartupMessages(library(ltm))\n",
    "suppressPackageStartupMessages(library(dplyr))\n",
    "suppressPackageStartupMessages(library(forcats))\n",
    "suppressPackageStartupMessages(library(\"plotly\"))\n",
    "\n",
    "source(\"data_cleaning.r\")\n",
    "survey_response_data <- get_survey_data_numerical()\n",
    "all_quant_responses <- names(survey_response_data)[sapply(survey_response_data, is.numeric)]\n",
    "\n",
    "source(\"constants.r\")\n",
    "question_labels <- get_question_labels()\n",
    "\n",
    "\n",
    "primmdebug_usability_questions <- c(\"Q1_1\",\"Q1_2\",\"Q1_3\",\"Q1_4\",\"Q1_5\")\n",
    "restrictive_factors_questions <- c(\"Q2_1\", \"Q2_2\", \"Q2_3\",\"Q2_4\")\n",
    "primmdebug_challenge_questions <- c(\"Q2_5\",\"Q3_1\",\"Q3_2\",\"Q4\")\n",
    "sifft_utility_questions <- c(\"Q5\",\"Q6\")\n",
    "likert_response_questions <- c(primmdebug_usability_questions, restrictive_factors_questions, primmdebug_challenge_questions, sifft_utility_questions) #TODO: Not sure where to put this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Summary Statistics\n",
    "We first report on overall statistics of the survey to give context to the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "source(\"constants.r\")\n",
    "\n",
    "paste(\"Number of student respondents: \", get_total_student_count())\n",
    "\n",
    "gender_count <- plot_ly(\n",
    "    x = get_gender_counts()$gender,\n",
    "    y = get_gender_counts()$count,\n",
    "    type = \"bar\"\n",
    ") %>% layout(title = \"Gender split of participating students\")\n",
    "gender_count\n",
    "\n",
    "year_group_count <- plot_ly(\n",
    "    x = get_year_group_split()$year_group,\n",
    "    y = get_year_group_split()$count,\n",
    "    type = \"bar\"\n",
    ") %>% layout(title = \"Year group of participating students\")\n",
    "year_group_count\n",
    "\n",
    "school_split <- plot_ly(\n",
    "    x = get_school_split()$school,\n",
    "    y = get_school_split()$count,\n",
    "    type = \"bar\"\n",
    ") %>% layout(title = \"School split of participating students\")\n",
    "school_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Factor Analysis\n",
    "Factor analysis was performed with the intention of investigating correlations between different groups of survey items (treated as latent factors), in order to uncover general patterns in responses to the survey items.\n",
    "\n",
    "The original intention was to perform confirmatory factor analysis (CFA) to identify the fitness of these factors and then if able, assess the correlations between them. However, Leonie et al., (2024), as well as other FA guides, suggests that this was not appropriate for out study for several reasons:\n",
    "- The factors used in CFA should be \"based on strong a-priori hypotheses\" (Leonie et al., 2024). We were not confident that the groupings of these hypotheses were strong enough for suitable confirmatory analysis. Combined with the relatively small number of student participants on which to perform factor analyis,\n",
    "- Factors could also be based on underlying theory or existing survey instruments. However, our survey was originally developed which is less suited to CFA given the lack of validation performed on it.\n",
    "\n",
    "The following steps document each step of the factor analysis we performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Transformation\n",
    "Since survey items use different Likert response options, the data needs to be transformed (Leonie et al., 2024). This was done by:\n",
    "- Normalising data to have the same min and max values. Given the closeness in range of Likert scale used (as well as the non-normal distributions of some responses), this was more appropriate than transformation.\n",
    "  - The `datawizard` package Patil (2022) was used to do this.\n",
    "- Reversing code negatively worded items? Will be able to tell from correlation\n",
    "(Can try the effect of standardisation on the output of the FA but it intuitively seems far less appropriate.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(\"datawizard\")\n",
    "normalised_likert_responses <- rescale(survey_response_data[, likert_response_questions], to = c(1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Safety Checks\n",
    "To verify whether EFA could be conducted, we performed the following safety checks, as discussed in Cohen et al., (2018) and Leonie et al., (2024):\n",
    "- A Bartlett's test of sphericity was performed to verify whether there are sufficiently large correlations between the survey items to warrant factor analysis. In order to perform FA, **a significant result (i.e., p < 0.05) was required** (Humble 2020, Leonie et al., 2024).\n",
    "- A Kaiser-Meyer-Olkin test was performed to measure the amount of common variance items among the survey items. According to Kaiser (1970, as cited in Humble, 2020) and Hutcheson and Sofroniou (1999, as cited in Humble, 2020), **we wanted a value above 0.7**.\n",
    "- The normality of the distributions was assessed through a visual inspection of the responses and measures of skewness/kurtosis.\n",
    "  - If data is not normally distributed, \"an estimation method that is robust against non-normality should be used\" (Leonie et al., 2024) - different type of estimator/extraction in factor analysis function\n",
    "\n",
    "Other tests to iron out:\n",
    "- Is the sample size sufficiently large?\n",
    "  - Given there are (n survey items reliable) and other items, how many participants is suitable?\n",
    "\n",
    "Note that responses to each survey item was compulsory, therefore there were no missing items in the matrix of responses.\n",
    "\n",
    "The correlation matrix used for the rest of the code is a *polychloric* matrix as we are dealing with ordinal data of varying scales (which has been normalised). Not only is this more appropriate, but ``the polychoric method of estimating correlation is more robust to the violation of normality assumption and could be preferably used, compared to the Pearson correlation, when data is not approximately normal and of ordinal level'' (p. 32, Emanuelsson, 2021). This is fitting given the non-normal distribution of some of the survey responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "suppressPackageStartupMessages(library(\"psych\"))\n",
    "source(\"analysis.r\")\n",
    "\n",
    "polychoric_matrix <- polychoric_correlation_matrix(normalised_likert_responses)\n",
    "\n",
    "cat(\"Cronbach's alpha across questions:\", internal_consistency(normalised_likert_responses), \"\\n\")\n",
    "\n",
    "cat(\"p-value from barlett test:\", round(cortest.bartlett(polychoric_matrix, n = get_total_student_count())$p.value, 3), \"\\n\") #TODO:Get correlation matrix to pass in here?\n",
    "\n",
    "cat(\"Overall MSA for likert scale responses in survey\", KMO(normalised_likert_responses)$MSA,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Extracting Factors\n",
    "\n",
    "If the safety checks in step (b) indicate factor analysis can be performed, we first need to determine how many factors we want to use. This is done through the following steps:\n",
    "1. A \"total variance explained\" table and Scree plot were generated.\n",
    "2. The eigenvalues and the Scree were plot inspected. These, along with the following considerations, were used to determine the number of factors:\n",
    "   - The number of factors suggested by parallel analysis.\n",
    "   - The Kaiser criterion - retain eigenvalues greater than one (Kaiser, 1970)\n",
    "   - The factors chosen should explain over 50% of the variance.\n",
    "3. Once the number of factors were decided, a component matrix was generated using the following parameters:\n",
    "   - Extraction/estimation method:\n",
    "      - Started with principal axis factoring as this is seemingly the most popular estimation method for non-normal distributed underlying data.\n",
    "      - This had to be done using the `fa` function in the `psych` package, which had the added bonus of being able to pass in my own polychloric matrix.\n",
    "      - Depending on results of this, explore with robust maximum likelihood (MLR, as used in Leonie et al., (2024)).\n",
    "      - Then, if FA is applicable, find out what other methods do not require the assumption of normal distribution.\n",
    "   - Rotation method: We were specifically interested in investigating the correlations between the factors; this was the entire goal of performing EFA. As a result, an oblique rotation method was entirely appropriate and recommended by Watkins (2018). We first tried **promax** and then **oblimin** due to their popularity and their general recommendation in Watkins (2018).\n",
    "These first three steps were replicated by a research colleague.\n",
    "1. The simplicity (where variables strongly/solely load onto a single factor, ideally with loadings of > 0.3) and the interpretability/logic of the factors (whether the survey items loaded onto a factor are logical) were consulted to decide the suitability of the model. If not suitable, the following parameters could be tuned:\n",
    "   - Number of factors in model.\n",
    "   - The rotation method.\n",
    "   - The extraction method.\n",
    "This exploration should help to inform the method of estimation and rotation to use for the EFA model created.\n",
    "\n",
    "If applicable, the final factor parameters are reported below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "suppressPackageStartupMessages(library(lavaan))\n",
    "suppressPackageStartupMessages(library(plotly))\n",
    "source(\"analysis.r\")\n",
    "\n",
    "eigenvalue <- eigen(polychoric_matrix)$values\n",
    "#eigen function only returns a vector of eigenvalues, so this is converted to a matrix with percentages/cumulative percentages\n",
    "variance_vector <- data.frame(eigenvalue)\n",
    "variance_vector$percent <- prop.table(variance_vector$eigenvalue) * 100\n",
    "variance_vector$cumulative_percent <- (cumsum(eigenvalue) / sum(eigenvalue)) * 100\n",
    "\n",
    "fig <- plot_ly(\n",
    "    type = \"table\",\n",
    "    columnwidth = c(100, 100, 100),\n",
    "    columnorder = c(0, 1, 2),\n",
    "    header = list(\n",
    "        values = colnames(variance_vector),\n",
    "        align = c(\"center\", \"center\", \"center\"),\n",
    "        line = list(width = 1, color = 'black'),\n",
    "        fill = list(color = c(\"grey\", \"grey\", \"grey\")),\n",
    "        font = list(family = \"Arial\", size = 14, color = \"white\")\n",
    "    ),\n",
    "    cells = list(\n",
    "        values = t(variance_vector),\n",
    "        align = c(\"center\", \"center\", \"center\"),\n",
    "        line = list(color = \"black\", width = 1)\n",
    "    )\n",
    ") %>%\n",
    "layout(title = \"Total variance explained - initial eigenvalues\")\n",
    "fig\n",
    "\n",
    "fa.parallel(normalised_likert_responses, fa=\"fa\", main=\"Scree plot for factor analysis\")\n",
    "\n",
    "efa_model <- fa(polychoric_matrix, nfactors = 2, fm = \"pa\", rotate = \"promax\", n.obs = get_total_student_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Inter-Factor Correlations\n",
    "If step (c) was completed, the interfactor correlation matrix was inspected using the `Phi` value of the `fa()` function, inspecting responses to individual items where necessary.. In the unlikely event that the correlation matrix has more than 20 items, some correction will be performed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(efa_model$Phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Alternative Extensions\n",
    "\n",
    "If factor analysis could not be performed, we planned to instead conduct some less advanced analysis inspired by visual inspection of the survey responses. This includes the following ideas:\n",
    "\n",
    "- Usability\n",
    "  - Calculate a mini-SUS score for the 5 survey items\n",
    "- SIFFT process\n",
    "  - How did usefulness of SIFFT process correlate with students' frequency of SIFFT?\n",
    "- Restrictive factors\n",
    "  - Correlational analysis (and internal consistency) on restrictive factors of PRIMMDebug (perhaps minus the find the error score)\n",
    "  - Perform correlation of this with gender\n",
    "- Correlational analysis between restrictive factors and utility of SIFFT (as these had the most negative responses)\n",
    "- General correlational analysis considerations\n",
    "  - Is there some way of aggregating a standardised score for each component of the survey?\n",
    "  - PCA with normalisation?\n",
    "  - Or create normalised Z-score? The higher the Z score, the more positive the perspectives\n",
    "    - Could these, or do some correlational analysis with gender\n",
    "- Support findings with short qual responses\n",
    "- Relation to student log data e.g. number of uses/challenges attempted?\n",
    "  - How did responses to restrictive factors (again, a score would be helpful), relate to the quality of students' reflections in PRIMMDebug?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Louis Cohen, Lawrence Manion, and Keith Morrison. 2017. Factor analysis, cluster analysis and structural equation modelling. In Research Methods in Education (8 ed.). Routledge, New York, Chapter 40, 753–775. https://doi.org/10.4324/9781315456539-43 \\\n",
    "Humble, S. (2020). Quantitative Analysis of Questionnaires: Techniques to Explore Structures and Relationships (1st ed.). Routledge. https://doi.org/10.4324/9780429400469 \\\n",
    "Hutcheson, G. D. (1999).  The multivariate social scientist. SAGE Publications, Ltd., https://doi.org/10.4135/9780857028075 \\\n",
    "Kaiser, H. F. (1970). A second generation little jiffy. Psychometrika, 35(4), 401–415. https://doi.org/10.1007/BF02291817\n",
    "Leonie V.D.E. Vogelsmeier, Mohammed Saqr, Sonsoles López-Pernas, Joran Jongerling (2024). Factor Analysis in Education Research Using R. In M. Saqr & S. López-Pernas (Eds.), Learning analytics methods and tutorials: A practical guide using R (pp. 673-703).Springer, Cham. doi: [10.1007/978-3-031-54464-4_20](https://link.springer.com/chapter/10.1007/978-3-031-54464-4_20) \\\n",
    "Patil I, Makowski D, Ben-Shachar MS, Wiernik BM, Bacher E, Lüdecke D (2022) Datawizard: An R package for easy data preparation and statistical transformations. J Open Source Softw 7:4684. https://doi.org/10.21105/joss.04684 \\\n",
    "Watkins, M. W. (2018). Exploratory Factor Analysis: A Guide to Best Practice. Journal of Black Psychology, 44(3), 219-246. https://doi.org/10.1177/0095798418771807 (Original work published 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix A. Visualisation of Individual Survey Item Responses\n",
    "We now provide some basic plots of the responses to individual Likert response items for comprehensiveness. Each question contains information on:\n",
    "- The normality of the distribution.\n",
    "- The skewness and kurtosis of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(moments)\n",
    "\n",
    "#Q1 responses\n",
    "question_1_items <- c(\"Q1_1\", \"Q1_2\", \"Q1_3\", \"Q1_4\", \"Q1_5\")\n",
    "\n",
    "fig_list <- list()\n",
    "for (question in question_1_items) {\n",
    "    cat(question_labels[question],\":\\n\")\n",
    "    cat(\"Skewness: \", round(skewness(table(factor(survey_response_data[, question], levels = 1:5))), 2), \"\\n\")\n",
    "    cat(\"Kurtosis: \", round(kurtosis(table(factor(survey_response_data[, question], levels = 1:5))), 2), \"\\n\")\n",
    "    fig <- plot_ly(\n",
    "        x = c(\"Strongly disagree\", \"Disagree\", \"Neither agree nor agree\", \"Agree\", \"Strongly agree\"),\n",
    "        y = table(factor(survey_response_data[, question], levels = 1:5)),\n",
    "        type = \"bar\",\n",
    "        name = question_labels[question],\n",
    "    ) %>%\n",
    "    layout(title = \"Hello\")\n",
    "    fig_list <- c(fig_list, list(fig))\n",
    "}\n",
    "\n",
    "subplot(fig_list, nrows = length(question_1_items), shareX = TRUE, shareY = TRUE) %>%\n",
    "    layout(title = question_labels[\"Q_1\"],\n",
    "           xaxis = list(categoryorder = \"array\", categoryarray = c(\"Strongly disagree\", \"Disagree\", \"Neither agree nor agree\", \"Agree\", \"Strongly agree\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Q2 responses\n",
    "question_2_items <- c(\"Q2_1\", \"Q2_2\", \"Q2_3\", \"Q2_4\", \"Q2_5\")\n",
    "fig_list <- list()\n",
    "for (question in question_2_items) {\n",
    "    cat(question_labels[question],\":\\n\")\n",
    "    cat(\"Skewness: \", round(skewness(table(factor(survey_response_data[, question], levels = 1:4))), 2), \"\\n\")\n",
    "    cat(\"Kurtosis: \", round(kurtosis(table(factor(survey_response_data[, question], levels = 1:4))), 2), \"\\n\")\n",
    "    fig <- plot_ly(\n",
    "        x = c(\"Very unhelpful\", \"Unhelpful\", \"Helpful\", \"Very helpful\"),\n",
    "        y = table(factor(survey_response_data[, question], levels = 1:4)),\n",
    "        type = \"bar\",\n",
    "        name = question_labels[question]\n",
    "    )\n",
    "    fig_list <- c(fig_list, list(fig))\n",
    "}\n",
    "\n",
    "subplot(fig_list, nrows = length(question_2_items), shareX = TRUE, shareY = TRUE) %>%\n",
    "    layout(title = question_labels[\"Q_2\"],\n",
    "           xaxis = list(categoryorder = \"array\", categoryarray = c(\"Very unhelpful\", \"Unhelpful\", \"Helpful\", \"Very helpful\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Q3 responses\n",
    "questions_3_items <- c(\"Q3_1\", \"Q3_2\")\n",
    "fig_list <- list()\n",
    "for (question in questions_3_items) {\n",
    "    cat(question_labels[question],\":\\n\")\n",
    "    cat(\"Skewness: \", round(skewness(table(factor(survey_response_data[, question], levels = 1:5))), 2), \"\\n\")\n",
    "    cat(\"Kurtosis: \", round(kurtosis(table(factor(survey_response_data[, question], levels = 1:5))), 2), \"\\n\")\n",
    "    fig <- plot_ly(\n",
    "        x = c(\"Strongly disagree\", \"Disagree\", \"Neither agree nor agree\", \"Agree\", \"Strongly agree\"),\n",
    "        y = table(factor(survey_response_data[, question], levels = 1:5)),\n",
    "        type = \"bar\",\n",
    "        name = question_labels[question])\n",
    "    fig_list <- c(fig_list, list(fig))\n",
    "}\n",
    "\n",
    "subplot(fig_list, nrows = length(questions_3_items), shareX = TRUE, shareY = TRUE) %>%\n",
    "    layout(title = question_labels[\"Q_3\"],\n",
    "            xaxis = list(categoryorder = \"array\", categoryarray = c(\"Strongly disagree\", \"Disagree\", \"Neither agree nor agree\", \"Agree\", \"Strongly agree\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Q4 responses\n",
    "cat(\"Skewness: \", round(skewness(table(factor(survey_response_data[, \"Q4\"], levels = 1:5))), 2), \"\\n\")\n",
    "cat(\"Kurtosis: \", round(kurtosis(table(factor(survey_response_data[, \"Q4\"], levels = 1:5))), 2), \"\\n\")\n",
    "fig <- plot_ly(\n",
    "    x = c(\"Far too challenging\", \"A little too challenging\", \"A good level of difficulty\", \"A little too easy\", \"Far too easy\"),\n",
    "    y = table(factor(survey_response_data[, \"Q4\"], levels = 1:5)),\n",
    "    type = \"bar\",\n",
    "    name = question_labels[\"Q4\"]) %>%\n",
    "        layout(title = question_labels[\"Q4\"],\n",
    "            xaxis = list(categoryorder = \"array\", categoryarray = c(\"Far too challenging\", \"A little too challenging\", \"A good level of difficulty\", \"A little too easy\", \"Far too easy\")))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Q5 responses\n",
    "cat(\"Skewness: \", round(skewness(table(factor(survey_response_data[, \"Q5\"], levels = 1:4))), 2), \"\\n\")\n",
    "cat(\"Kurtosis: \", round(kurtosis(table(factor(survey_response_data[, \"Q5\"], levels = 1:4))), 2), \"\\n\")\n",
    "fig <- plot_ly(\n",
    "    x = c(\"Not at all\", \"I barely use it\", \"I sometimes use it\", \"I use it every time I get an error\"),\n",
    "    y = table(factor(survey_response_data[, \"Q5\"], levels = 1:4)),\n",
    "    type = \"bar\",\n",
    "    name = question_labels[\"Q5\"]\n",
    ") %>%\n",
    "    layout(title = question_labels[\"Q5\"],\n",
    "           xaxis = list(categoryorder = \"array\", categoryarray = c(\"Not at all\", \"I barely use it\", \"I sometimes use it\", \"I use it every time I get an error\")))\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Q6 responses\n",
    "cat(\"Skewness: \", round(skewness(table(factor(survey_response_data[, \"Q6\"], levels = 1:4))), 2), \"\\n\")\n",
    "cat(\"Kurtosis: \", round(kurtosis(table(factor(survey_response_data[, \"Q6\"], levels = 1:4))), 2), \"\\n\")\n",
    "fig <- plot_ly(\n",
    "    x = c(\"Very unhelpful\", \"Unhelpful\", \"Helpful\", \"Very helpful\"),\n",
    "    y = table(factor(survey_response_data[, \"Q6\"], levels = 1:4)),\n",
    "    type = \"bar\",\n",
    "    name = question_labels[\"Q6\"]\n",
    ") %>%\n",
    "    layout(title = question_labels[\"Q6\"],\n",
    "           xaxis = list(categoryorder = \"array\", categoryarray = c(\"Very unhelpful\", \"Unhelpful\", \"Helpful\", \"Very helpful\")))\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix B. Written Responses\n",
    "The following code cell displays the written feedback that students gave in response to the optional free-text question \"If there's anything else you'd like to mention about PRIMMDebug or SIFFT, please write it here.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "for (i in 1:nrow(survey_response_data)) {\n",
    "    if (survey_response_data[i, \"Q7\"] != \"\") {\n",
    "        print(paste(survey_response_data[i, \"Q7\"]))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix C. Original FA Plan\n",
    "\n",
    "We initially grouped the survey responses into some groups based on the content of the survey items:\n",
    "- **Usability**: The usability of programs, borrowing items from the [System Usability Scale](https://en.wikipedia.org/wiki/System_usability_scale).\n",
    "- **Utility: Restrictive Factors**: Perceived utility of the parts of the PRIMMDebug tool that restricted students' \"programming autonomy\".\n",
    "- **Utility: PRIMMDebug Challenges**: Perceived utility of the PRIMMDebug challenges they attempted.\n",
    "- **Utility: SIFFT**: Perceived utility of the SIFFT process that teachers taught for debugging.\n",
    "\n",
    "Each of these constructs Likert scale response questions associated with them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
