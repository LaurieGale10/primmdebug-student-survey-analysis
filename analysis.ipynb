{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRIMMDebug Student Survey Analysis\n",
    "\n",
    "This notebook contains a narrative of the code used to analyse the responses from the student survey taken after usage of PRIMMDebug. The goal of the survey was to understand students' perspectives towards PRIMMDebug, which could be triangulated with their actions within the PRIMMDebug tool.\n",
    "\n",
    "The analysis is split up into several sections:\n",
    "1. Summary statistics across the whole dataset.\n",
    "2. Factor analysis\n",
    "3. (Potentially) Alternative analysis\n",
    "4. An appendix of visualisations for each individual question response.\n",
    "\n",
    "First, let us import the necessary libraries and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(ltm)\n",
    "library(dplyr)\n",
    "library(forcats)\n",
    "library(\"plotly\")\n",
    "\n",
    "source(\"data_cleaning.r\")\n",
    "survey_response_data <- get_survey_data_numerical()\n",
    "all_quant_responses <- names(survey_response_data)[sapply(survey_response_data, is.numeric)]\n",
    "\n",
    "source(\"constants.r\")\n",
    "question_labels <- get_question_labels()\n",
    "\n",
    "\n",
    "primmdebug_usability_questions <- c(\"Q1_1\",\"Q1_2\",\"Q1_3\",\"Q1_4\",\"Q1_5\")\n",
    "restrictive_factors_questions <- c(\"Q2_1\", \"Q2_2\", \"Q2_3\",\"Q2_4\")\n",
    "primmdebug_challenge_questions <- c(\"Q2_5\",\"Q3_1\",\"Q3_2\",\"Q4\")\n",
    "sifft_utility_questions <- c(\"Q5\",\"Q6\")\n",
    "likert_response_questions <- c(primmdebug_usability_questions, restrictive_factors_questions, primmdebug_challenge_questions, sifft_utility_questions) #TODO: Not sure where to put this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Summary Statistics\n",
    "We first report on overall statistics of the survey to give context to the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "source(\"constants.r\")\n",
    "\n",
    "paste(\"Number of student respondents: \", get_total_student_count())\n",
    "\n",
    "gender_count <- plot_ly(\n",
    "    x = get_gender_counts()$gender,\n",
    "    y = get_gender_counts()$count,\n",
    "    type = \"bar\"\n",
    ") %>% layout(title = \"Gender split of participating students\")\n",
    "gender_count\n",
    "\n",
    "year_group_count <- plot_ly(\n",
    "    x = get_year_group_split()$year_group,\n",
    "    y = get_year_group_split()$count,\n",
    "    type = \"bar\"\n",
    ") %>% layout(title = \"Year group of participating students\")\n",
    "year_group_count\n",
    "\n",
    "school_split <- plot_ly(\n",
    "    x = get_school_split()$school,\n",
    "    y = get_school_split()$count,\n",
    "    type = \"bar\"\n",
    ") %>% layout(title = \"School split of participating students\")\n",
    "school_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Factor Analysis\n",
    "Factor analysis was performed with the intention of investigating correlations between different groups of survey items (treated as latent factors), in order to uncover general patterns in responses to the survey items.\n",
    "\n",
    "The original intention was to perform confirmatory factor analysis (CFA) to identify the fitness of these factors and then if able, assess the correlations between them. However, Leonie et al., (2024), as well as other FA guides, suggests that this was not appropriate for out study for several reasons:\n",
    "- The factors used in CFA should be \"based on strong a-priori hypotheses\" (Leonie et al., 2024). We were not confident that the groupings of these hypotheses were strong enough for suitable confirmatory analysis. Combined with the relatively small number of student participants on which to perform factor analyis,\n",
    "- Factors could also be based on underlying theory or existing survey instruments. However, our survey was originally developed which is less suited to CFA given the lack of validation performed on it.\n",
    "\n",
    "The following steps document each step of the factor analysis we performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Transformation\n",
    "Since survey items use different Likert response options, the data needs to be transformed (Leonie et al., 2024). This was done by:\n",
    "- Normalising data to have the same min and max values. Given the closeness in range of Likert scale used (as well as the non-normal distributions of some responses), this was more appropriate than transformation.\n",
    "  - The `datawizard` package Patil (2022) was used to do this.\n",
    "- Reversing code negatively worded items? Will be able to tell from correlation\n",
    "(Can try the effect of standardisation on the output of the FA but it intuitively seems far less appropriate.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(\"datawizard\")\n",
    "normalised_likert_responses <- rescale(survey_response_data[, likert_response_questions], to = c(1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Safety Checks\n",
    "To verify whether EFA could be conducted, we performed the following safety checks, as discussed in Cohen et al., (2018) and Leonie et al., (2024):\n",
    "- A Bartlett's test of sphericity was performed to verify whether there are sufficiently large correlations between the survey items to warrant factor analysis. In order to perform FA, **a significant result (i.e., p < 0.05) was required** (Humble 2020, Leonie et al., 2024).\n",
    "- A Kaiser-Meyer-Olkin test was performed to measure the amount of common variance items among the survey items. According to Kaiser (1970, as cited in Humble, 2020) and Hutcheson and Sofroniou (1999, as cited in Humble, 2020), **we wanted a value above 0.7**.\n",
    "- The normality of the distributions was assessed through a visual inspection of the responses and measures of skewness/kurtosis.\n",
    "  - If data is not normally distributed, \"an estimation method that is robust against non-normality should be used\" (Leonie et al., 2024) - different type of estimator/extraction in factor analysis function\n",
    "\n",
    "Other tests to iron out:\n",
    "- Is the sample size sufficiently large?\n",
    "  - Given there are (n survey items reliable) and other items, how many participants is suitable?\n",
    "\n",
    "Note that responses to each survey item was compulsory, therefore there were no missing items in the matrix of responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(\"psych\")\n",
    "source(\"analysis.r\")\n",
    "\n",
    "cat(\"Cronbach's alpha across questions:\", internal_consistency(normalised_likert_responses), \"\\n\")\n",
    "\n",
    "cat(\"p-value from barlett test:\", round(cortest.bartlett(correlation_matrix(normalised_likert_responses), n = get_total_student_count())$p.value, 3), \"\\n\") #TODO:Get correlation matrix to pass in here?\n",
    "\n",
    "cat(\"Overall MSA for likert scale responses in survey\", KMO(normalised_likert_responses)$MSA,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Extracting Factors\n",
    "\n",
    "If the safety checks in step (b) indicate factor analysis can be performed, we first need to determine how many factors we want to use. This is done through the following steps:\n",
    "1. A \"total variance explained\" table and Scree plot were generated.\n",
    "2. The eigenvalues and the Scree were plot inspected. These, along with the following considerations, were used to determine the number of factors:\n",
    "   - The number of factors suggested by parallel analysis.\n",
    "   - The Kaiser criterion - retain eigenvalues greater than one (Kaiser, 1970)\n",
    "   - The factors chosen should explain over 50% of the variance.\n",
    "3. Once the number of factors were decided, a component matrix was generated using the following parameters:\n",
    "   - Extraction/estimation method: Needs to be something that does not assume normality - principal factor analysis/robust maximum likelihood\n",
    "   - Rotation method: Consult lavaan tutorial, but needs to be one that allows/assumes correlation between variables (i.e. oblique)\n",
    "These first three steps were replicated by a research colleague.\n",
    "4. The simplicity (where variables strongly/solely load onto a single factor, ideally with loadings of > 0.3) and the interpretability/logic of the factors (whether the survey items loaded onto a factor are logical) were consulted to decide the suitability of the model. If not suitable, the following parameters could be tuned:\n",
    "   - Number of factors in model.\n",
    "   - The rotation method.\n",
    "   - The extraction method.\n",
    "This exploration should help to inform the method of estimation and rotation to use for the EFA model created.\n",
    "5. If applicable, the final factor parameters are reported below, leading to the factors of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(jmv)\n",
    "source(\"analysis.r\")\n",
    "\n",
    "eigenvalue <- eigen(correlation_matrix(normalised_likert_responses))$values\n",
    "#eigen function only returns a vector of eigenvalues, so this is converted to a matrix with percentages/cumulative percentages\n",
    "variance_vector <- data.frame(eigenvalue)\n",
    "variance_vector$percent <- prop.table(variance_vector$eigenvalue) * 100\n",
    "variance_vector$cumulative_percent <- (cumsum(eigenvalue) / sum(eigenvalue)) * 100\n",
    "\n",
    "print(\"Total variance explained - initial eigenvalues\")\n",
    "print(variance_vector) #Needs converting to table\n",
    "\n",
    "fa.parallel(normalised_likert_responses, fa=\"fa\", main=\"Scree plot for factor analysis\")\n",
    "\n",
    "efa_model <- efa(data = normalised_likert_responses, nfactors = 2:5)\n",
    "efa_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Inter-Factor Correlations\n",
    "If step (c) was completed, a Pearson correlation matrix comparing each latent factor was then generated. In the unlikely event that the correlation matrix has more than 20 items, some correction will be performed.\n",
    "\n",
    "Correlations between factors will then be inspected, inspecting responses to individual items where necessary.\n",
    "\n",
    "- How to find correlation between factors rather than correlations between items and factors? Is this a separate step?\n",
    "- Should CFA be performed with this model? Is this always possible or dependent on the rotation/estimation method used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Alternative Extensions\n",
    "\n",
    "If factor analysis could not be performed, we planned to instead conduct some less advanced analysis inspired by visual inspection of the survey responses. This includes the following ideas:\n",
    "\n",
    "- Calculate a mini-SUS score for the 5 survey items\n",
    "- Correlational analysis (and internal consistency) on restrive factors of PRIMMDebug (perhaps minus the find the error score)\n",
    "  - Perform correlation of this with gender\n",
    "- Correlational analysis between restrictive factors and utility of SIFFT (as these had the most negative responses)\n",
    "- What else???\n",
    "- Light coding of qual responses (sentiment analysis/mapping to survey particular survey items/groups of survey items?)\n",
    "- Relation to student log data e.g. number of uses/challenges attempted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Louis Cohen, Lawrence Manion, and Keith Morrison. 2017. Factor analysis, cluster analysis and structural equation modelling. In Research Methods in Education (8 ed.). Routledge, New York, Chapter 40, 753–775. https://doi.org/10.4324/9781315456539-43 \\\n",
    "Humble, S. (2020). Quantitative Analysis of Questionnaires: Techniques to Explore Structures and Relationships (1st ed.). Routledge. https://doi.org/10.4324/9780429400469 \\\n",
    "Hutcheson, G. D. (1999).  The multivariate social scientist. SAGE Publications, Ltd., https://doi.org/10.4135/9780857028075 \\\n",
    "Kaiser, H. F. (1970). A second generation little jiffy. Psychometrika, 35(4), 401–415. https://doi.org/10.1007/BF02291817\n",
    "Leonie V.D.E. Vogelsmeier, Mohammed Saqr, Sonsoles López-Pernas, Joran Jongerling (2024). Factor Analysis in Education Research Using R. In M. Saqr & S. López-Pernas (Eds.), Learning analytics methods and tutorials: A practical guide using R (pp. 673-703).Springer, Cham. doi: [10.1007/978-3-031-54464-4_20](https://link.springer.com/chapter/10.1007/978-3-031-54464-4_20) \\\n",
    "Patil I, Makowski D, Ben-Shachar MS, Wiernik BM, Bacher E, Lüdecke D (2022) Datawizard: An R package for easy data preparation and statistical transformations. J Open Source Softw 7:4684. https://doi.org/10.21105/joss.04684"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix A. Visualisation of Individual Survey Item Responses\n",
    "We now provide some basic plots of the responses to individual Likert response items for comprehensiveness. Each question contains information on:\n",
    "- The normality of the distribution.\n",
    "- The skewness and kurtosis of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(moments)\n",
    "\n",
    "#Q1 responses\n",
    "question_1_items <- c(\"Q1_1\", \"Q1_2\", \"Q1_3\", \"Q1_4\", \"Q1_5\")\n",
    "\n",
    "fig_list <- list()\n",
    "for (question in question_1_items) {\n",
    "    cat(question_labels[question],\":\\n\")\n",
    "    cat(\"Skewness: \", round(skewness(table(factor(survey_response_data[, question], levels = 1:5))), 2), \"\\n\")\n",
    "    cat(\"Kurtosis: \", round(kurtosis(table(factor(survey_response_data[, question], levels = 1:5))), 2), \"\\n\")\n",
    "    fig <- plot_ly(\n",
    "        x = c(\"Strongly disagree\", \"Disagree\", \"Neither agree nor agree\", \"Agree\", \"Strongly agree\"),\n",
    "        y = table(factor(survey_response_data[, question], levels = 1:5)),\n",
    "        type = \"bar\",\n",
    "        name = question_labels[question],\n",
    "    ) %>%\n",
    "    layout(title = \"Hello\")\n",
    "    fig_list <- c(fig_list, list(fig))\n",
    "}\n",
    "\n",
    "subplot(fig_list, nrows = length(question_1_items), shareX = TRUE, shareY = TRUE) %>%\n",
    "    layout(title = question_labels[\"Q_1\"],\n",
    "           xaxis = list(categoryorder = \"array\", categoryarray = c(\"Strongly disagree\", \"Disagree\", \"Neither agree nor agree\", \"Agree\", \"Strongly agree\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Q2 responses\n",
    "question_2_items <- c(\"Q2_1\", \"Q2_2\", \"Q2_3\", \"Q2_4\", \"Q2_5\")\n",
    "fig_list <- list()\n",
    "for (question in question_2_items) {\n",
    "    cat(question_labels[question],\":\\n\")\n",
    "    cat(\"Skewness: \", round(skewness(table(factor(survey_response_data[, question], levels = 1:4))), 2), \"\\n\")\n",
    "    cat(\"Kurtosis: \", round(kurtosis(table(factor(survey_response_data[, question], levels = 1:4))), 2), \"\\n\")\n",
    "    fig <- plot_ly(\n",
    "        x = c(\"Very unhelpful\", \"Unhelpful\", \"Helpful\", \"Very helpful\"),\n",
    "        y = table(factor(survey_response_data[, question], levels = 1:4)),\n",
    "        type = \"bar\",\n",
    "        name = question_labels[question]\n",
    "    )\n",
    "    fig_list <- c(fig_list, list(fig))\n",
    "}\n",
    "\n",
    "subplot(fig_list, nrows = length(question_2_items), shareX = TRUE, shareY = TRUE) %>%\n",
    "    layout(title = question_labels[\"Q_2\"],\n",
    "           xaxis = list(categoryorder = \"array\", categoryarray = c(\"Very unhelpful\", \"Unhelpful\", \"Helpful\", \"Very helpful\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Q3 responses\n",
    "questions_3_items <- c(\"Q3_1\", \"Q3_2\")\n",
    "fig_list <- list()\n",
    "for (question in questions_3_items) {\n",
    "    cat(question_labels[question],\":\\n\")\n",
    "    cat(\"Skewness: \", round(skewness(table(factor(survey_response_data[, question], levels = 1:5))), 2), \"\\n\")\n",
    "    cat(\"Kurtosis: \", round(kurtosis(table(factor(survey_response_data[, question], levels = 1:5))), 2), \"\\n\")\n",
    "    fig <- plot_ly(\n",
    "        x = c(\"Strongly disagree\", \"Disagree\", \"Neither agree nor agree\", \"Agree\", \"Strongly agree\"),\n",
    "        y = table(factor(survey_response_data[, question], levels = 1:5)),\n",
    "        type = \"bar\",\n",
    "        name = question_labels[question])\n",
    "    fig_list <- c(fig_list, list(fig))\n",
    "}\n",
    "\n",
    "subplot(fig_list, nrows = length(questions_3_items), shareX = TRUE, shareY = TRUE) %>%\n",
    "    layout(title = question_labels[\"Q_3\"],\n",
    "            xaxis = list(categoryorder = \"array\", categoryarray = c(\"Strongly disagree\", \"Disagree\", \"Neither agree nor agree\", \"Agree\", \"Strongly agree\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Q4 responses\n",
    "cat(\"Skewness: \", round(skewness(table(factor(survey_response_data[, \"Q4\"], levels = 1:5))), 2), \"\\n\")\n",
    "cat(\"Kurtosis: \", round(kurtosis(table(factor(survey_response_data[, \"Q4\"], levels = 1:5))), 2), \"\\n\")\n",
    "fig <- plot_ly(\n",
    "    x = c(\"Far too challenging\", \"A little too challenging\", \"A good level of difficulty\", \"A little too easy\", \"Far too easy\"),\n",
    "    y = table(factor(survey_response_data[, \"Q4\"], levels = 1:5)),\n",
    "    type = \"bar\",\n",
    "    name = question_labels[\"Q4\"]) %>%\n",
    "        layout(title = question_labels[\"Q4\"],\n",
    "            xaxis = list(categoryorder = \"array\", categoryarray = c(\"Far too challenging\", \"A little too challenging\", \"A good level of difficulty\", \"A little too easy\", \"Far too easy\")))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Q5 responses\n",
    "cat(\"Skewness: \", round(skewness(table(factor(survey_response_data[, \"Q5\"], levels = 1:4))), 2), \"\\n\")\n",
    "cat(\"Kurtosis: \", round(kurtosis(table(factor(survey_response_data[, \"Q5\"], levels = 1:4))), 2), \"\\n\")\n",
    "fig <- plot_ly(\n",
    "    x = c(\"Not at all\", \"I barely use it\", \"I sometimes use it\", \"I use it every time I get an error\"),\n",
    "    y = table(factor(survey_response_data[, \"Q5\"], levels = 1:4)),\n",
    "    type = \"bar\",\n",
    "    name = question_labels[\"Q5\"]\n",
    ") %>%\n",
    "    layout(title = question_labels[\"Q5\"],\n",
    "           xaxis = list(categoryorder = \"array\", categoryarray = c(\"Not at all\", \"I barely use it\", \"I sometimes use it\", \"I use it every time I get an error\")))\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Q6 responses\n",
    "cat(\"Skewness: \", round(skewness(table(factor(survey_response_data[, \"Q6\"], levels = 1:4))), 2), \"\\n\")\n",
    "cat(\"Kurtosis: \", round(kurtosis(table(factor(survey_response_data[, \"Q6\"], levels = 1:4))), 2), \"\\n\")\n",
    "fig <- plot_ly(\n",
    "    x = c(\"Very unhelpful\", \"Unhelpful\", \"Helpful\", \"Very helpful\"),\n",
    "    y = table(factor(survey_response_data[, \"Q6\"], levels = 1:4)),\n",
    "    type = \"bar\",\n",
    "    name = question_labels[\"Q6\"]\n",
    ") %>%\n",
    "    layout(title = question_labels[\"Q6\"],\n",
    "           xaxis = list(categoryorder = \"array\", categoryarray = c(\"Very unhelpful\", \"Unhelpful\", \"Helpful\", \"Very helpful\")))\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix B. Written Responses\n",
    "The following code cell displays the written feedback that students gave in response to the optional free-text question \"If there's anything else you'd like to mention about PRIMMDebug or SIFFT, please write it here.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "for (i in 1:nrow(survey_response_data)) {\n",
    "    if (survey_response_data[i, \"Q7\"] != \"\") {\n",
    "        print(paste(survey_response_data[i, \"Q7\"]))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix C. Original FA Plan\n",
    "\n",
    "We initially grouped the survey responses into some groups based on the content of the survey items:\n",
    "- **Usability**: The usability of programs, borrowing items from the [System Usability Scale](https://en.wikipedia.org/wiki/System_usability_scale).\n",
    "- **Utility: Restrictive Factors**: Perceived utility of the parts of the PRIMMDebug tool that restricted students' \"programming autonomy\".\n",
    "- **Utility: PRIMMDebug Challenges**: Perceived utility of the PRIMMDebug challenges they attempted.\n",
    "- **Utility: SIFFT**: Perceived utility of the SIFFT process that teachers taught for debugging.\n",
    "\n",
    "Each of these constructs Likert scale response questions associated with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "source(\"analysis.r\")\n",
    "\n",
    "cat(\"Cronbach's alpha for primmdebug_usability_questions factor:\", internal_consistency(survey_response_data, primmdebug_usability_questions), \"\\n\")\n",
    "cat(\"Cronbach's alpha for restrictive_factors_questions factor:\", internal_consistency(survey_response_data, restrictive_factors_questions), \"\\n\")\n",
    "cat(\"Cronbach's alpha for primmdebug_challenge_questions factor:\", internal_consistency(survey_response_data, primmdebug_challenge_questions), \"\\n\")\n",
    "cat(\"Cronbach's alpha for sifft_utility_questions factor:\", internal_consistency(survey_response_data, sifft_utility_questions), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
